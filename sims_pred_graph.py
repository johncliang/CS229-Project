"""Script that trains Sklearn regression models on PDBbind Pockets dataset."""from __future__ import print_functionfrom __future__ import divisionfrom __future__ import unicode_literals__author__ = "Jay Liu, Vamsi Varanasi, JC Liang"# Modified from scripts by:# __author__ = "Bharath Ramsundar"# __copyright__ = "Copyright 2017, Stanford University"# __license__ = "MIT"import osimport deepchem as dcimport numpy as npimport sklearnimport csvimport timefrom binding_pocket_datasets import load_pdbbind_pocketsimport matplotlib.pyplot as pltstart = time.time()# Print error metrics to csv filedef calc_metrics(train_dataset, valid_dataset, transformers, trainrow, validrow):    for met in ['rms_score', 'mae_score', 'pearson_r2_score', 'r2_score']:        if met == 'rms_score':            metric = dc.metrics.Metric(dc.metrics.rms_score)        elif met == 'mae_score':            metric = dc.metrics.Metric(dc.metrics.mae_score)        elif met == 'pearson_r2_score':            metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)        elif met == 'r2_score':            metric = dc.metrics.Metric(dc.metrics.r2_score)        print("Train scores")        train_scores = model.evaluate(train_dataset, [metric], transformers)        trainrow.append(train_scores)        print("Validation scores")        valid_scores = model.evaluate(valid_dataset, [metric], transformers)        validrow.append(valid_scores)    return trainrow, validrowdef calc_pred(test_dataset, transformers, test_row):    for met in ['rms_score', 'mae_score', 'pearson_r2_score', 'r2_score']:        if met == 'rms_score':            metric = dc.metrics.Metric(dc.metrics.rms_score)        elif met == 'mae_score':            metric = dc.metrics.Metric(dc.metrics.mae_score)        elif met == 'pearson_r2_score':            metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)        elif met == 'r2_score':            metric = dc.metrics.Metric(dc.metrics.r2_score)        print("Test scores")        test_scores = model.evaluate(test_dataset, [metric], transformers)        test_row.append(test_scores)    return test_row# For stable runs#np.random.seed(123)# Load datasetssplit = "random"subset = "refined"pdbbind_tasks, pdbbind_datasets, transformers = load_pdbbind_pockets(    split=split, subset=subset)train_dataset, valid_dataset, test_dataset = pdbbind_datasetscurrent_dir = os.path.dirname(os.path.realpath(__file__))with open(subset + '_metrics_pred.csv', mode='w') as model_metrics:    writer = csv.writer(model_metrics, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)    writer.writerow(['Model', 'Data', 'RMS', 'MAE', 'Pearson R2', 'R2'])    # Random Forests    for n_est in [10, 20, 50, 100, 200, 500, 1000]:        model_type = "RF"        sklearn_model = sklearn.ensemble.RandomForestRegressor(n_estimators=n_est)        model_dir = os.path.join(current_dir, "%s_models/pocket_%s_%s_%s_%s" % (subset, split, subset, model_type, n_est))        model = dc.models.SklearnModel(sklearn_model, model_dir=model_dir)        # Fit trained model        # print("Fitting model on train dataset")        model.fit(train_dataset)        model.save()        trainrow = ['RF ' + str(n_est), 'Train']        validrow = ['', 'Valid']        print("Evaluating model " + 'RF' + str(n_est))        trainrow, validrow = calc_metrics(train_dataset, valid_dataset, transformers, trainrow, validrow)        writer.writerow(trainrow)        writer.writerow(validrow)        # Make predictions        testrow = ['', 'Test']        testrow = calc_pred(test_dataset, transformers, testrow)        writer.writerow(testrow)        # Generate parity plots        for dataset in [train_dataset, valid_dataset, test_dataset]:            type = "Training: "            if dataset == valid_dataset:                type = "Validation: "            if dataset == test_dataset:                type = "Testing: "            y_test = model.predict(dataset)            plt.clf()            plt.scatter(dataset.y, y_test, color='blue')            plt.line            plt.title('%s_%s_%s_%s_%s' % (type, split, subset, model_type, n_est))            plt.xlabel('Experimental')            plt.ylabel('Predictions')            plt_dir = os.path.join(current_dir, "plots_%s/pocket_%s_%s_%s_%s_%s" % (subset, type, split, subset, model_type, n_est))            plt.savefig(plt_dir)    # Kernel SVMs    for kernel in ['linear', 'poly', 'rbf', 'sigmoid']:        model_type = "SVM"        sklearn_model = sklearn.svm.SVR(kernel=kernel)        model_dir = os.path.join(current_dir, "%s_models/pocket_%s_%s_%s_%s" % (subset, split, subset, model_type, kernel))        model = dc.models.SklearnModel(sklearn_model, model_dir=model_dir)        # Fit trained model        # print("Fitting model on train dataset")        model.fit(train_dataset)        model.save()        trainrow = ['SVR ' + kernel, 'Train']        validrow = ['', 'Valid']        print("Evaluating model " + 'SVR ' + kernel)        trainrow, validrow = calc_metrics(train_dataset, valid_dataset, transformers, trainrow, validrow)        writer.writerow(trainrow)        writer.writerow(validrow)        # Make predictions        testrow = ['', 'Test']        testrow = calc_pred(test_dataset, transformers, testrow)        writer.writerow(testrow)        # Generate parity plots        for dataset in [train_dataset, valid_dataset, test_dataset]:            type = "Training: "            if dataset == valid_dataset:                type = "Validation: "            if dataset == test_dataset:                type = "Testing: "            y_test = model.predict(dataset)            plt.clf()            plt.scatter(dataset.y, y_test, color='green')            plt.title('%s_%s_%s_%s_%s' % (type, split, subset, model_type, kernel))            plt.xlabel('Experimental')            plt.ylabel('Predictions')            plt_dir = os.path.join(current_dir, "plots_%s/pocket_%s_%s_%s_%s_%s" % (subset, type, split, subset, model_type, kernel))            plt.savefig(plt_dir)    # Kernel Ridge Regression    for kernel in ['linear', 'poly', 'rbf', 'sigmoid', 'laplacian']:        model_type = "KRR"        sklearn_model = sklearn.kernel_ridge.KernelRidge(kernel=kernel)        model_dir = os.path.join(current_dir, "%s_models/pocket_%s_%s_%s_%s" % (subset, split, subset, model_type, kernel))        model = dc.models.SklearnModel(sklearn_model, model_dir=model_dir)        # Fit trained model        # print("Fitting model on train dataset")        model.fit(train_dataset)        model.save()        trainrow = ['KRR ' + kernel, 'Train']        validrow = ['', 'Valid']        print("Evaluating model " + 'KRR ' + kernel)        trainrow, validrow = calc_metrics(train_dataset, valid_dataset, transformers, trainrow, validrow)        writer.writerow(trainrow)        writer.writerow(validrow)        # Make predictions        testrow = ['', 'Test']        testrow = calc_pred(test_dataset, transformers, testrow)        writer.writerow(testrow)        # Generate parity plots        for dataset in [train_dataset, valid_dataset, test_dataset]:            type = "Training: "            if dataset == valid_dataset:                type = "Validation: "            if dataset == test_dataset:                type = "Testing: "            y_test = model.predict(dataset)            plt.clf()            plt.scatter(dataset.y, y_test, color='red')            plt.title('%s_%s_%s_%s_%s' % (type, split, subset, model_type, kernel))            plt.xlabel('Experimental')            plt.ylabel('Predictions')            plt_dir = os.path.join(current_dir, "plots_%s/pocket_%s_%s_%s_%s_%s" % (subset, type, split, subset, model_type, kernel))            plt.savefig(plt_dir)tot_time = time.time() - startprint("Compute time = " + str(tot_time) + ' sec')